{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xQa6VlNAOe"
   },
   "source": [
    "# Download the MovieLens-100K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0mG3n0qRNTSA",
    "outputId": "56efc043-224c-49c3-a020-4f8f95b10a6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens 100K dataset into a dataframe of pandas\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFJT0QWudp1P"
   },
   "outputs": [],
   "source": [
    "# Select 500 most active users and 500 most active items from the dataset\n",
    "n_most_active_users = 500\n",
    "n_most_active_items = 500\n",
    "\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(n_most_active_users).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(n_most_active_items).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r012fu0jJkJc"
   },
   "outputs": [],
   "source": [
    "# Map new internal ID for items\n",
    "i_ids = df['item_id'].unique().tolist()\n",
    "item_dict = dict(zip(i_ids, [i for i in range(len(i_ids))]))\n",
    "df['item_id'] = df['item_id'].map(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ3rlC7jO6WJ"
   },
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwS00lvHO-ca",
    "outputId": "a1bbd1cf-45d3-43cf-c69d-c18883349258"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fb140fbf3b12>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
      "<ipython-input-4-fb140fbf3b12>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n"
     ]
    }
   ],
   "source": [
    "# The number of training users and active users\n",
    "n_training_users = 300\n",
    "n_active_users = n_most_active_users - n_training_users\n",
    "\n",
    "# The number of GIVEN ratings for active users\n",
    "GIVEN = 20\n",
    "\n",
    "# Randomly select users from the most active users as training set\n",
    "random_uids = np.random.choice(df.user_id.unique(), n_training_users, replace=False)\n",
    "train_df = df[df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all users in the training set\n",
    "u_ids = train_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
    "\n",
    "# The rest of users are active users for testing\n",
    "remain_df = df[~df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all active users\n",
    "u_ids = remain_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n",
    "\n",
    "# Randomly select GIVEN ratings for active users\n",
    "active_df = remain_df.groupby('user_id').sample(n=GIVEN, random_state=1024)\n",
    "\n",
    "test_df = remain_df[~remain_df.index.isin(active_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-ke62G3jiYb",
    "outputId": "7d702607-0f52-42de-be3a-3c55a7c5ea8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 1        4.0  0.0  5.0  0.0  0.0  3.0  4.0  2.0  0.0  2.0  ...  0.0  2.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  5.0  5.0  0.0  3.0  5.0  0.0  ...  0.0  4.0  0.0   \n",
       " 3        0.0  0.0  0.0  5.0  4.0  4.0  0.0  0.0  0.0  5.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  4.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  4.0  ...  0.0  0.0  3.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 295      4.0  0.0  4.0  0.0  0.0  4.0  3.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 296      0.0  0.0  5.0  4.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " 297      4.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 298      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 299      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  4.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  4.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  3.0  0.0  3.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  2.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 295      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 296      0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       " 297      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 298      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 299      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [300 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  4.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  4.0   \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  4.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  2.0  0.0  4.0  0.0  4.0  0.0  0.0  0.0  2.0  ...  0.0  4.0  4.0   \n",
       " 2        0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        4.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        4.0  0.0  5.0  0.0  1.0  0.0  3.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      4.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  5.0  0.0  0.0  0.0  4.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  4.0  5.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  0.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  4.0  0.0  3.0  0.0  \n",
       " 1        0.0  3.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        4.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  4.0  2.0  3.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 199      5.0  0.0  0.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format of datasets to matrices\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_training_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_training_users), 'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_active_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_active_users), 'rating': 0})\n",
    "active_ds = df_zeros.merge(active_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "test_ds = df_zeros.merge(test_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "train_ds, active_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy4FurbHD4dt"
   },
   "source": [
    "# Algorithm that you need to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "zYh1bVd0ncz3",
    "outputId": "441582da-9471-4d77-db5e-e92125f8fcde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.224719</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.307692</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.874647</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.994085</td>\n",
       "      <td>2.878049</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>4.074074</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.161290</td>\n",
       "      <td>1.239088</td>\n",
       "      <td>4.169421</td>\n",
       "      <td>2.931034</td>\n",
       "      <td>3.679737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>2.477002</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.874647</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.765957</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.342878</td>\n",
       "      <td>3.981593</td>\n",
       "      <td>3.156220</td>\n",
       "      <td>1.820865</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.931034</td>\n",
       "      <td>1.705810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.375511</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.924124</td>\n",
       "      <td>4.185191</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.261290</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.393315</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.941064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.043478</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.180592</td>\n",
       "      <td>2.878049</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.587755</td>\n",
       "      <td>2.161290</td>\n",
       "      <td>3.401805</td>\n",
       "      <td>3.470539</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.625815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.584754</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.241596</td>\n",
       "      <td>3.395747</td>\n",
       "      <td>3.657221</td>\n",
       "      <td>3.533828</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.662102</td>\n",
       "      <td>2.537958</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.943897</td>\n",
       "      <td>2.675406</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.892008</td>\n",
       "      <td>3.168247</td>\n",
       "      <td>2.856635</td>\n",
       "      <td>3.017338</td>\n",
       "      <td>2.813486</td>\n",
       "      <td>3.087558</td>\n",
       "      <td>3.144278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.477002</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.874647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.144336</td>\n",
       "      <td>2.878049</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>4.395050</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.261290</td>\n",
       "      <td>2.747183</td>\n",
       "      <td>3.169421</td>\n",
       "      <td>2.931034</td>\n",
       "      <td>1.692655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>3.276001</td>\n",
       "      <td>1.970600</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.645833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.043478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.388100</td>\n",
       "      <td>1.761770</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.156877</td>\n",
       "      <td>2.426667</td>\n",
       "      <td>2.261290</td>\n",
       "      <td>1.808079</td>\n",
       "      <td>2.736219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.431598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>3.645833</td>\n",
       "      <td>3.234522</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.765957</td>\n",
       "      <td>2.520084</td>\n",
       "      <td>3.260912</td>\n",
       "      <td>4.849807</td>\n",
       "      <td>3.100100</td>\n",
       "      <td>2.161290</td>\n",
       "      <td>2.636559</td>\n",
       "      <td>2.808316</td>\n",
       "      <td>2.931034</td>\n",
       "      <td>3.670467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4.297266</td>\n",
       "      <td>4.432506</td>\n",
       "      <td>4.496675</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.123601</td>\n",
       "      <td>4.702862</td>\n",
       "      <td>4.210114</td>\n",
       "      <td>4.903579</td>\n",
       "      <td>3.942894</td>\n",
       "      <td>4.903579</td>\n",
       "      <td>...</td>\n",
       "      <td>3.809638</td>\n",
       "      <td>4.087383</td>\n",
       "      <td>4.030767</td>\n",
       "      <td>4.273906</td>\n",
       "      <td>3.686870</td>\n",
       "      <td>3.678238</td>\n",
       "      <td>3.729851</td>\n",
       "      <td>4.336236</td>\n",
       "      <td>3.909161</td>\n",
       "      <td>3.734818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4.224719</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>3.645833</td>\n",
       "      <td>3.307692</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.036574</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>2.161290</td>\n",
       "      <td>1.436718</td>\n",
       "      <td>3.016730</td>\n",
       "      <td>2.931034</td>\n",
       "      <td>3.431598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    4.224719  3.333333  0.000000  3.958333  5.000000  3.307692  3.934211   \n",
       "1    4.000000  3.333333  5.000000  3.958333  2.477002  3.000000  4.000000   \n",
       "2    5.000000  3.333333  0.000000  2.333333  5.000000  5.000000  3.934211   \n",
       "3    5.000000  3.333333  0.000000  5.000000  4.000000  4.000000  3.934211   \n",
       "4    3.584754  4.000000  3.241596  3.395747  3.657221  3.533828  3.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  4.000000  3.333333  4.000000  4.333333  3.477002  4.000000  3.000000   \n",
       "296  3.276001  1.970600  5.000000  4.000000  3.645833  1.000000  3.934211   \n",
       "297  4.000000  3.333333  3.000000  3.958333  3.645833  3.234522  3.934211   \n",
       "298  4.297266  4.432506  4.496675  5.000000  4.123601  4.702862  4.210114   \n",
       "299  4.224719  1.000000  0.000000  3.958333  3.645833  3.307692  3.934211   \n",
       "\n",
       "          7         8         9    ...       490       491       492  \\\n",
       "0    0.000000  3.874647  4.000000  ...  2.994085  2.878049  3.866667   \n",
       "1    2.000000  1.874647  2.000000  ...  2.765957  2.000000  3.342878   \n",
       "2    3.000000  5.000000  0.000000  ...  3.375511  4.000000  4.924124   \n",
       "3    0.000000  3.043478  5.000000  ...  3.180592  2.878049  3.866667   \n",
       "4    3.662102  2.537958  4.000000  ...  2.943897  2.675406  3.000000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  4.000000  2.874647  0.000000  ...  4.144336  2.878049  2.166667   \n",
       "296  0.000000  3.043478  1.000000  ...  1.388100  1.761770  3.866667   \n",
       "297  0.000000  3.043478  0.000000  ...  2.765957  2.520084  3.260912   \n",
       "298  4.903579  3.942894  4.903579  ...  3.809638  4.087383  4.030767   \n",
       "299  0.000000  3.043478  0.000000  ...  3.000000  4.000000  3.866667   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    4.074074  3.200000  2.161290  1.239088  4.169421  2.931034  3.679737  \n",
       "1    3.981593  3.156220  1.820865  0.858333  4.000000  2.931034  1.705810  \n",
       "2    4.185191  3.200000  2.261290  3.000000  4.393315  3.000000  1.941064  \n",
       "3    5.000000  2.587755  2.161290  3.401805  3.470539  2.000000  3.625815  \n",
       "4    2.892008  3.168247  2.856635  3.017338  2.813486  3.087558  3.144278  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  4.395050  3.200000  2.261290  2.747183  3.169421  2.931034  1.692655  \n",
       "296  3.156877  2.426667  2.261290  1.808079  2.736219  1.000000  1.431598  \n",
       "297  4.849807  3.100100  2.161290  2.636559  2.808316  2.931034  3.670467  \n",
       "298  4.273906  3.686870  3.678238  3.729851  4.336236  3.909161  3.734818  \n",
       "299  3.036574  2.866667  2.161290  1.436718  3.016730  2.931034  3.431598  \n",
       "\n",
       "[300 rows x 500 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Put all your implementation for your algorithm in this cell only to handle the missing values; \n",
    "## and please DO NOT change anything in the rest of the cells in this framework. \n",
    "\n",
    "## Note: \n",
    "## The user-item rating matrix is train_ds, and the missing values are those 0s in train_ds. \n",
    "\n",
    "## The following parameters are required in the given report \"\", please do not change them. \n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ITA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "\n",
    "# Compute Pearson Correlation Coefficient for All Pairs of Users in training set\n",
    "user_pearson_corr = np.zeros((train_ds.shape[0], train_ds.shape[0]))\n",
    "\n",
    "for i, user_i_vec in enumerate(train_ds.values):\n",
    "    for j, user_j_vec in enumerate(train_ds.values):\n",
    "\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "\n",
    "# Compute Pearson Correlation Coefficient for All Pairs of Items in training set\n",
    "item_pearson_corr = np.zeros((train_ds.shape[1], train_ds.shape[1]))\n",
    "\n",
    "for i, item_i_vec in enumerate(train_ds.T.values):\n",
    "    for j, item_j_vec in enumerate(train_ds.T.values):\n",
    "\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        # ratings corated by the current pair od items\n",
    "        mask_i = item_i_vec > 0\n",
    "        mask_j = item_j_vec > 0\n",
    "\n",
    "        # corrated index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of item_i_vec and item_j_vec\n",
    "        mean_item_i = np.sum(item_i_vec) / (np.sum(np.clip(item_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_item_j = np.sum(item_j_vec) / (np.sum(np.clip(item_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        item_i_sub_mean = item_i_vec[corrated_index] - mean_item_i\n",
    "        item_j_sub_mean = item_j_vec[corrated_index] - mean_item_j\n",
    "\n",
    "        r_ui_sub_ri_sq = np.square(item_i_sub_mean)\n",
    "        r_uj_sub_rj_sq = np.square(item_j_sub_mean)\n",
    "\n",
    "        r_ui_sub_ri_sq_sum_sqrt = np.sqrt(np.sum(r_ui_sub_ri_sq))\n",
    "        r_uj_sub_rj_sq_sum_sqrt = np.sqrt(np.sum(r_uj_sub_rj_sq))\n",
    "\n",
    "        sim = np.sum(item_i_sub_mean * item_j_sub_mean) / (r_ui_sub_ri_sq_sum_sqrt * r_uj_sub_rj_sq_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), DELTA) / DELTA) * sim\n",
    "\n",
    "        item_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "\n",
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(train_ds.values):\n",
    "    if rating > 0:\n",
    "        continue\n",
    "    sim_user_ids = np.where(user_pearson_corr[i] > ITA)[0]\n",
    "    sim_item_ids = np.where(item_pearson_corr[j] > THETA)[0]\n",
    "\n",
    "    if len(sim_user_ids) > 0 and len(sim_item_ids) > 0:\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(train_ds.values[i]) / (np.sum(np.clip(train_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        #==================item-based==================#\n",
    "        # the coefficient values of similar items\n",
    "        sim_val = item_pearson_corr[j][sim_item_ids]\n",
    "\n",
    "        # the average value of the current item's ratings\n",
    "        sim_items = train_ds.T.values[sim_item_ids]\n",
    "        item_mean = np.sum(train_ds.T.values[j]) / (np.sum(np.clip(train_ds.T.values[j], 0, 1)) + EPSILON)\n",
    "        sim_item_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # sim(u, v) * (r_v - mean_v)\n",
    "        sim_r_sum_mean = sim_val * (sim_items[:, i] - sim_item_mean) \n",
    "\n",
    "        # filter unrated items\n",
    "        w = np.clip(sim_items[:, i], 0, 1)\n",
    "        sim_r_sum_mean *= w\n",
    "\n",
    "        item_based_pred = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val * w) + EPSILON)    \n",
    "        item_based_pred = np.clip(item_based_pred, 0, 5)\n",
    "\n",
    "        imputed_train_ds[i][j] = LAMBDA * user_based_pred + (1 - LAMBDA) * item_based_pred\n",
    "\n",
    "    if len(sim_user_ids) > 0 and len(sim_item_ids) == 0:\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(train_ds.values[i]) / (np.sum(np.clip(train_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        imputed_train_ds[i][j] = user_based_pred\n",
    "    \n",
    "    if len(sim_user_ids) == 0 and len(sim_item_ids) > 0:\n",
    "        #==================item-based==================#\n",
    "        # the coefficient values of similar items\n",
    "        sim_val = item_pearson_corr[j][sim_item_ids]\n",
    "\n",
    "        # the average value of the current item's ratings\n",
    "        sim_items = train_ds.T.values[sim_item_ids]\n",
    "        item_mean = np.sum(train_ds.T.values[j]) / (np.sum(np.clip(train_ds.T.values[j], 0, 1)) + EPSILON)\n",
    "        sim_item_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # sim(u, v) * (r_v - mean_v)\n",
    "        sim_r_sum_mean = sim_val * (sim_items[:, i] - sim_item_mean) \n",
    "\n",
    "        # filter unrated items\n",
    "        w = np.clip(sim_items[:, i], 0, 1)\n",
    "        sim_r_sum_mean *= w\n",
    "\n",
    "        item_based_pred = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val * w) + EPSILON)    \n",
    "        item_based_pred = np.clip(item_based_pred, 0, 5)\n",
    "        \n",
    "        imputed_train_ds[i][j] = item_based_pred\n",
    "        \n",
    "imputed_train_ds = pd.DataFrame(imputed_train_ds)\n",
    "imputed_train_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOfVWTV_Aij"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txs8YjwTzuSP"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0uq1aHzu11",
    "outputId": "d0c227b6-d655-482c-8ab8-90430bd03a56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  2.31472290e-01, -1.95760684e-01, ...,\n",
       "        -6.60895559e-02,  1.17677792e-01, -3.79290715e-01],\n",
       "       [-1.29397347e-01,  0.00000000e+00,  1.89826929e-01, ...,\n",
       "         2.01058086e-01,  6.58238709e-02,  4.82247840e-02],\n",
       "       [-3.57056212e-02,  2.63336521e-01,  0.00000000e+00, ...,\n",
       "         1.51089219e-01,  1.79837871e-01,  3.09124939e-02],\n",
       "       ...,\n",
       "       [-1.83995613e-01,  2.88952749e-01, -1.52412416e-01, ...,\n",
       "         0.00000000e+00, -4.08620055e-10, -4.30270005e-01],\n",
       "       [-1.68880626e-01,  6.41550043e-02,  0.00000000e+00, ...,\n",
       "        -1.96464476e-01,  0.00000000e+00, -3.80446161e-02],\n",
       "       [-1.69460879e-01,  1.96843792e-01,  9.99999997e-02, ...,\n",
       "         1.99906694e-01,  1.93676411e-01,  0.00000000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_item_pearson_corr = np.zeros((active_ds.shape[1], imputed_train_ds.shape[1]))\n",
    "\n",
    "# Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set\n",
    "for i, item_i_vec in enumerate(active_ds.T.values):\n",
    "    for j, item_j_vec in enumerate(imputed_train_ds.T.values):\n",
    "\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        # Put all your implementation for your algorithm here\n",
    "        # active_item_pearson_corr[i, j] = ?\n",
    "\n",
    "        # ratings corated by the current pair od items\n",
    "        mask_i = item_i_vec > 0\n",
    "        mask_j = item_j_vec > 0\n",
    "\n",
    "        # corrated index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of item_i_vec and item_j_vec\n",
    "        mean_item_i = np.sum(item_i_vec) / (np.sum(np.clip(item_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_item_j = np.sum(item_j_vec) / (np.sum(np.clip(item_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        item_i_sub_mean = item_i_vec[corrated_index] - mean_item_i\n",
    "        item_j_sub_mean = item_j_vec[corrated_index] - mean_item_j\n",
    "\n",
    "        r_ui_sub_ri_sq = np.square(item_i_sub_mean)\n",
    "        r_uj_sub_rj_sq = np.square(item_j_sub_mean)\n",
    "\n",
    "        r_ui_sub_ri_sq_sum_sqrt = np.sqrt(np.sum(r_ui_sub_ri_sq))\n",
    "        r_uj_sub_rj_sq_sum_sqrt = np.sqrt(np.sum(r_uj_sub_rj_sq))\n",
    "\n",
    "        sim = np.sum(item_i_sub_mean * item_j_sub_mean) / (r_ui_sub_ri_sq_sum_sqrt * r_uj_sub_rj_sq_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), DELTA) / DELTA) * sim\n",
    "\n",
    "        active_item_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "active_item_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTnN9kNb8Ys"
   },
   "source": [
    "## Predict Ratings of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_item_ids = np.argsort(active_item_pearson_corr[j])[-10:]\n",
    "\n",
    "        #==================item-based==================#\n",
    "        # the coefficient values of similar items\n",
    "        sim_val = active_item_pearson_corr[j][sim_item_ids]\n",
    "\n",
    "        # the average value of the current item's ratings\n",
    "        sim_items = train_ds.T.values[sim_item_ids]\n",
    "        item_mean = np.sum(active_ds.T.values[j]) / (np.sum(np.clip(active_ds.T.values[j], 0, 1)) + EPSILON)\n",
    "        sim_item_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # sim(u, v) * (r_v - mean_v)\n",
    "        sim_r_sum_mean = sim_val * (sim_items[:, i] - sim_item_mean) \n",
    "\n",
    "        # filter unrated items\n",
    "        w = np.clip(sim_items[:, i], 0, 1)\n",
    "        sim_r_sum_mean *= w\n",
    "\n",
    "        item_based_pred = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val * w) + EPSILON)    \n",
    "        item_based_pred = np.clip(item_based_pred, 0, 5)\n",
    "\n",
    "        test_ds_pred[i][j] = item_based_pred\n",
    "\n",
    "        \n",
    "test_ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ERndYXb8Ys",
    "outputId": "e292c95d-8c24-457e-dae9-ae342305df87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , ..., 0.   , 3.165, 0.   ],\n",
       "       [0.   , 3.34 , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 4.1  , ..., 0.   , 0.   , 0.   ],\n",
       "       ...,\n",
       "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_user_ids = np.where(active_user_pearson_corr[i] > ITA)[0]\n",
    "        sim_item_ids = np.where(active_item_pearson_corr[j] > THETA)[0]\n",
    "\n",
    "        if len(sim_user_ids) == 0 and len(sim_item_ids) == 0:\n",
    "            # Put all your implementation for your algorithm here\n",
    "            # test_ds_pred[i, j] = ?\n",
    "            user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "            item_mean = np.sum(active_ds.values.T[j]) / (np.sum(np.clip(active_ds.values.T[j], 0, 1)) + EPSILON)\n",
    "            test_ds_pred[i][j] = LAMBDA * user_mean + (1 - LAMBDA) * item_mean\n",
    "\n",
    "        if len(sim_user_ids) > 0 and len(sim_item_ids) > 0:\n",
    "            # Put all your implementation for your algorithm here\n",
    "            # test_ds_pred[i, j] = ?\n",
    "            #==================user-based==================#\n",
    "            # the coefficient values of similar users\n",
    "            sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "            # the average value of the current user's ratings\n",
    "            sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "            user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "            sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "            # select the users who rated item j\n",
    "            mask_rated_j = sim_users[:, j] > 0\n",
    "            \n",
    "            # sim(u, v) * (r_vj - mean_v)\n",
    "            sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "            \n",
    "            user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "            user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "            #==================item-based==================#\n",
    "            # the coefficient values of similar items\n",
    "            sim_val = active_item_pearson_corr[j][sim_item_ids]\n",
    "\n",
    "            # the average value of the current item's ratings\n",
    "            sim_items = imputed_train_ds.T.values[sim_item_ids]\n",
    "            item_mean = np.sum(active_ds.T.values[j]) / (np.sum(np.clip(active_ds.T.values[j], 0, 1)) + EPSILON)\n",
    "            sim_item_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "            # sim(u, v) * (r_v - mean_v)\n",
    "            sim_r_sum_mean = sim_val * (sim_items[:, i] - sim_item_mean) \n",
    "\n",
    "            # filter unrated items\n",
    "            w = np.clip(sim_items[:, i], 0, 1)\n",
    "            sim_r_sum_mean *= w\n",
    "\n",
    "            item_based_pred = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val * w) + EPSILON)    \n",
    "            item_based_pred = np.clip(item_based_pred, 0, 5)\n",
    "\n",
    "            test_ds_pred[i][j] = LAMBDA * user_based_pred + (1 - LAMBDA) * item_based_pred\n",
    "\n",
    "        if len(sim_user_ids) > 0 and len(sim_item_ids) == 0:\n",
    "            # Put all your implementation for your algorithm here\n",
    "            # test_ds_pred[i, j] = ?\n",
    "            #==================user-based==================#\n",
    "            # the coefficient values of similar users\n",
    "            sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "            # the average value of the current user's ratings\n",
    "            sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "            user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "            sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "            # select the users who rated item j\n",
    "            mask_rated_j = sim_users[:, j] > 0\n",
    "            \n",
    "            # sim(u, v) * (r_vj - mean_v)\n",
    "            sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "            \n",
    "            user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "            user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "            test_ds_pred[i][j] = user_based_pred\n",
    "        \n",
    "        if len(sim_user_ids) == 0 and len(sim_item_ids) > 0:\n",
    "            # Put all your implementation for your algorithm here\n",
    "            # test_ds_pred[i, j] = ?\n",
    "            #==================item-based==================#\n",
    "            # the coefficient values of similar items\n",
    "            sim_val = active_item_pearson_corr[j][sim_item_ids]\n",
    "\n",
    "            # the average value of the current item's ratings\n",
    "            sim_items = imputed_train_ds.T.values[sim_item_ids]\n",
    "            item_mean = np.sum(active_ds.T.values[j]) / (np.sum(np.clip(active_ds.T.values[j], 0, 1)) + EPSILON)\n",
    "            sim_item_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "            # sim(u, v) * (r_v - mean_v)\n",
    "            sim_r_sum_mean = sim_val * (sim_items[:, i] - sim_item_mean) \n",
    "\n",
    "            # filter unrated items\n",
    "            w = np.clip(sim_items[:, i], 0, 1)\n",
    "            sim_r_sum_mean *= w\n",
    "\n",
    "            item_based_pred = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val * w) + EPSILON)    \n",
    "            item_based_pred = np.clip(item_based_pred, 0, 5)\n",
    "            \n",
    "            test_ds_pred[i][j] = item_based_pred\n",
    "        \n",
    "test_ds_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUTn4kSFb8ZA"
   },
   "source": [
    "## Compute MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JCVmexyb8ZA",
    "outputId": "485345dd-bdaf-4fd0-9be5-87f5fb243418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8197537148201074, RMSE: 1.0419547104577915\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "MAE = np.sum(np.abs(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1))\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(np.square(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1)))\n",
    "\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3_solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
